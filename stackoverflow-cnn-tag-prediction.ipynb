{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import requests\n",
    "\n",
    "\n",
    "REPOSITORY_PATH = \"https://github.com/hse-aml/natural-language-processing\"\n",
    "\n",
    "\n",
    "def download_file(url, file_path):\n",
    "    r = requests.get(url, stream=True)\n",
    "    total_size = int(r.headers.get('content-length'))\n",
    "    try:\n",
    "        with open(file_path, 'wb', buffering=16*1024*1024) as f:\n",
    "\n",
    "            for chunk in r.iter_content(32 * 1024):\n",
    "                f.write(chunk)\n",
    "                \n",
    "    except Exception:\n",
    "        print(\"Download failed\")\n",
    "    finally:\n",
    "        if os.path.getsize(file_path) != total_size:\n",
    "            os.remove(file_path)\n",
    "            print(\"Removed incomplete download\")\n",
    "\n",
    "\n",
    "def download_from_github(version, fn, target_dir, force=False):\n",
    "    url = REPOSITORY_PATH + \"/releases/download/{0}/{1}\".format(version, fn)\n",
    "    file_path = os.path.join(target_dir, fn)\n",
    "    if os.path.exists(file_path) and not force:\n",
    "        print(\"File {} is already downloaded.\".format(file_path))\n",
    "        return\n",
    "    download_file(url, file_path)\n",
    "\n",
    "\n",
    "def sequential_downloader(version, fns, target_dir, force=False):\n",
    "    os.makedirs(target_dir, exist_ok=True)\n",
    "    for fn in fns:\n",
    "        download_from_github(version, fn, target_dir, force=force)\n",
    "\n",
    "\n",
    "def download_resources(force=False):\n",
    "    sequential_downloader(\n",
    "        \"week1\",\n",
    "        [\n",
    "            \"train.tsv\",\n",
    "            \"validation.tsv\",\n",
    "            \"test.tsv\",\n",
    "            \"text_prepare_tests.tsv\",\n",
    "        ],\n",
    "        \"data\",\n",
    "        force=force\n",
    "    )\n",
    "\n",
    "\n",
    "def download_project_resources(force=False):\n",
    "    sequential_downloader(\n",
    "        \"project\",\n",
    "        [\n",
    "            \"dialogues.tsv\",\n",
    "            \"tagged_posts.tsv\",\n",
    "        ],\n",
    "        \"data\",\n",
    "        force=force\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File data\\train.tsv is already downloaded.\n",
      "File data\\validation.tsv is already downloaded.\n",
      "File data\\test.tsv is already downloaded.\n",
      "File data\\text_prepare_tests.tsv is already downloaded.\n"
     ]
    }
   ],
   "source": [
    "download_resources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "regex_pat = re.compile(r'\\'')\n",
    "\n",
    "def read_data(filename):\n",
    "    data = pd.read_csv(filename, sep='\\t', encoding='utf-8')\n",
    "    data['tags'] = data['tags'].apply(literal_eval)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>Obj-c, incorrect checksum for freed object - o...</td>\n",
       "      <td>[iphone, objective-c, ios, cocoa-touch]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>How to connect via HTTPS using Jsoup?</td>\n",
       "      <td>[java, android]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>Python Pandas Series of Datetimes to Seconds S...</td>\n",
       "      <td>[python, datetime, pandas]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>jqGrid issue grouping - Duplicate rows get app...</td>\n",
       "      <td>[javascript, jquery]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>Create a List of primitive int?</td>\n",
       "      <td>[java, list, generics]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "99995  Obj-c, incorrect checksum for freed object - o...   \n",
       "99996              How to connect via HTTPS using Jsoup?   \n",
       "99997  Python Pandas Series of Datetimes to Seconds S...   \n",
       "99998  jqGrid issue grouping - Duplicate rows get app...   \n",
       "99999                    Create a List of primitive int?   \n",
       "\n",
       "                                          tags  \n",
       "99995  [iphone, objective-c, ios, cocoa-touch]  \n",
       "99996                          [java, android]  \n",
       "99997               [python, datetime, pandas]  \n",
       "99998                     [javascript, jquery]  \n",
       "99999                   [java, list, generics]  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindf = read_data(\"./data/train.tsv\")\n",
    "validdf = read_data(\"./data/validation.tsv\")\n",
    "test = pd.read_csv('./data/test.tsv', sep='\\t')\n",
    "traindf.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from collections import Counter\n",
    "\n",
    "tags_counts = Counter()\n",
    "\n",
    "for tags in traindf['tags'].values:\n",
    "    for tag in tags:\n",
    "        tags_counts[tag] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'javascript': 19078, 'c#': 19077, 'java': 18661, 'php': 13907, 'python': 8940, 'jquery': 7510, 'c++': 6469, 'html': 4668, 'objective-c': 4338, 'asp.net': 3939, '.net': 3872, 'ruby-on-rails': 3344, 'ios': 3256, 'c': 3119, 'mysql': 3092, 'android': 2818, 'ruby': 2326, 'arrays': 2277, 'json': 2026, 'vb.net': 1918, 'iphone': 1909, 'django': 1835, 'css': 1769, 'ajax': 1767, 'r': 1727, 'string': 1573, 'winforms': 1468, 'swift': 1465, 'regex': 1442, 'angularjs': 1353, 'xml': 1347, 'spring': 1346, 'wpf': 1289, 'sql': 1272, 'asp.net-mvc': 1244, 'multithreading': 1118, 'eclipse': 992, 'linq': 964, 'xcode': 900, 'forms': 872, 'html5': 842, 'windows': 838, 'hibernate': 807, 'linux': 793, 'codeigniter': 786, 'node.js': 771, 'swing': 759, 'database': 740, 'list': 693, 'ruby-on-rails-3': 692, 'jsp': 680, 'image': 672, 'entity-framework': 649, 'web-services': 633, 'spring-mvc': 618, 'visual-studio-2010': 588, 'sql-server': 585, 'file': 582, 'sockets': 579, 'visual-studio': 574, 'date': 560, 'validation': 558, 'datetime': 557, 'laravel': 525, 'performance': 512, 'class': 509, 'facebook': 508, 'cocoa-touch': 507, 'numpy': 502, 'twitter-bootstrap': 501, 'servlets': 498, 'osx': 490, 'function': 487, 'pandas': 479, 'wordpress': 478, 'uitableview': 460, 'rest': 456, 'qt': 451, 'unit-testing': 449, 'excel': 443, 'apache': 441, 'xaml': 438, 'csv': 435, 'maven': 432, 'selenium': 431, 'oop': 425, 'python-2.7': 421, 'generics': 420, 'algorithm': 419, 'session': 415, 'google-maps': 408, 'parsing': 403, 'opencv': 401, 'dom': 400, 'wcf': 389, 'loops': 389, 'python-3.x': 379, 'sorting': 375, 'mongodb': 350, 'pointers': 350})\n"
     ]
    }
   ],
   "source": [
    "print(tags_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "traindf = traindf.join(pd.DataFrame(mlb.fit_transform(traindf['tags'].values),\n",
    "                                #columns = mlb.classes_,\n",
    "                              columns=sorted(tags_counts.keys()),\n",
    "                              index=traindf.index))\n",
    "traindf.drop('tags',axis=1,inplace=True)\n",
    "\n",
    "validdf = validdf.join(pd.DataFrame(mlb.fit_transform(validdf['tags'].values),\n",
    "                                #columns = mlb.classes_,\n",
    "                              columns=sorted(tags_counts.keys()),\n",
    "                              index=validdf.index))\n",
    "validdf.drop('tags',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf.to_csv('./data/train_prepped.tsv',index=False, header=True, sep=\"\\t\")\n",
    "validdf.to_csv('./data/valid_prepped.tsv',index=False, header=True, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "from torchtext import data\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = data.Field(tokenize = 'spacy')\n",
    "LABEL = data.Field(sequential=False, \n",
    "                         use_vocab=False, \n",
    "                         pad_token=None, \n",
    "                            unk_token=None)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sorted_tag_lst = sorted(list(tags_counts.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TagsMultiLabelDataset(torchtext.data.Dataset):\n",
    "    def __init__(self, df, tt_text_field, tt_label_field, txt_col, lbl_cols, **kwargs):\n",
    "#         dataFields = [(\"text\", TEXT)]\n",
    "\n",
    "#         for i in tags_counts:\n",
    "#             dataFields.append((i, LABEL))\n",
    "        \n",
    "        #torchtext Field objects\n",
    "        fields = [('text', tt_text_field)]\n",
    "        for l in lbl_cols: fields.append((l, tt_label_field))\n",
    "        \n",
    "        \n",
    "        \n",
    "        is_test = False if lbl_cols[0] in df.columns else True\n",
    "        n_labels = len(lbl_cols)\n",
    "        \n",
    "        examples = []\n",
    "        for idx, row in df.iterrows():\n",
    "            if not is_test:\n",
    "                lbls = [ row[l] for l in lbl_cols ]\n",
    "            else:\n",
    "                lbls = [0.0] * n_labels\n",
    "                \n",
    "            txt = str(row[txt_col])\n",
    "            \n",
    "            examples.append(data.Example.fromlist([txt]+lbls, fields))\n",
    "        fields = dict(fields)                   \n",
    "        super().__init__(examples, fields, **kwargs)\n",
    "\n",
    "    @staticmethod\n",
    "    def sort_key(example): \n",
    "        return len(example.text)\n",
    "    \n",
    "    @classmethod\n",
    "    def splits(cls, text_field, label_field, train_df, txt_col, lbl_cols, val_df=None, test_df=None, **kwargs):\n",
    "        # build train, val, and test data\n",
    "        train_data, val_data, test_data = (None, None, None)\n",
    "        \n",
    "        if train_df is not None: \n",
    "            train_data = cls(train_df.copy(), text_field, label_field, txt_col, lbl_cols, **kwargs)\n",
    "        if val_df is not None: \n",
    "            val_data = cls(val_df.copy(), text_field, label_field, txt_col, lbl_cols, **kwargs)\n",
    "        if test_df is not None: \n",
    "            test_data = cls(test_df.copy(), text_field, label_field, txt_col, lbl_cols, **kwargs)\n",
    "\n",
    "        return tuple(d for d in (train_data, val_data, test_data) if d is not None)\n",
    "    \n",
    "    \n",
    "class TextMultiLabelDataLoader():\n",
    "    def __init__(self, src, x_fld, y_flds, y_dtype='torch.cuda.FloatTensor'):\n",
    "        self.src, self.x_fld, self.y_flds = src, x_fld, y_flds\n",
    "        self.y_dtype = y_dtype\n",
    "\n",
    "    def __len__(self): return len(self.src)#-1\n",
    "\n",
    "    def __iter__(self):\n",
    "        it = iter(self.src)\n",
    "        for i in range(len(self)):\n",
    "            b = next(it)\n",
    "            \n",
    "            if (len(self.y_flds) > 1):\n",
    "                targ = [ getattr(b, y) for y in self.y_flds ] \n",
    "                targ = torch.stack(targ, dim=1).type(self.y_dtype)\n",
    "            else: \n",
    "                targ = getattr(b, self.y_flds[0])\n",
    "                targ = targ.type(self.y_dtype)\n",
    "\n",
    "            yield getattr(b, self.x_fld), targ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(traindf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data= TagsMultiLabelDataset(traindf[:int(len(traindf)*0.5)],TEXT,LABEL,'title',sorted_tag_lst)\n",
    "\n",
    "valid_data= TagsMultiLabelDataset(validdf[:int(len(traindf)*0.3)],TEXT,LABEL,'title',sorted_tag_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "30000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data))\n",
    "print(len(valid_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_VOCAB_SIZE = 10_000\n",
    "\n",
    "TEXT.build_vocab(train_data, \n",
    "                 max_size = MAX_VOCAB_SIZE, \n",
    "                 vectors = \"glove.6B.100d\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator = data.Iterator(train_data, batch_size=128, device=device, shuffle=False)\n",
    "valid_iterator = data.Iterator(valid_data, batch_size=1024, device=device, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['How', 'to', 'draw', 'a', 'stacked', 'dotplot', 'in', 'R', '?']\n"
     ]
    }
   ],
   "source": [
    "print(train_iterator.dataset.examples[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import re\n",
    "\n",
    "#re.sub(r'[\\[,\\s\\]\\']', '', train_iterator.dataset.examples[0].label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10002"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TEXT.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "train_iterator.create_batches()\n",
    "for batch in train_iterator.batches:\n",
    "    print(getattr(batch[0],['.net','java'][0]))\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "train_iterator.create_batches()\n",
    "for batch in train_iterator:\n",
    "    print(getattr(batch,'.net'))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, \n",
    "                 dropout, pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.convs = nn.ModuleList([\n",
    "                                    nn.Conv2d(in_channels = 1, \n",
    "                                              out_channels = n_filters, \n",
    "                                              kernel_size = (fs, embedding_dim)) \n",
    "                                    for fs in filter_sizes\n",
    "                                    ])\n",
    "        \n",
    "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        \n",
    "        #text = [sent len, batch size]\n",
    "        text = text.permute(1, 0)\n",
    "        #text = [batch size, sent len]\n",
    "        embedded = self.embedding(text)\n",
    "        #embedded = [batch size, sent len, emb dim]\n",
    "        \n",
    "        embedded = embedded.unsqueeze(1)\n",
    "        \n",
    "        #embedded = [batch size, 1, sent len, emb dim]\n",
    "        \n",
    "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
    "            \n",
    "        #conv_n = [batch size, n_filters, sent len - filter_sizes[n]]\n",
    "        \n",
    "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "        \n",
    "        #pooled_n = [batch size, n_filters]\n",
    "        \n",
    "        cat = self.dropout(torch.cat(pooled, dim = 1))\n",
    "\n",
    "        #cat = [batch size, n_filters * len(filter_sizes)]\n",
    "            \n",
    "        return self.fc(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10002"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TEXT.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 300 #\n",
    "N_FILTERS = 100\n",
    "FILTER_SIZES = [2,3,4]\n",
    "OUTPUT_DIM = len(sorted_tag_lst)\n",
    "DROPOUT = 0.5\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "model = CNN(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT, PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 3,301,000 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pretrained_embeddings = TEXT.vocab.vectors\n",
    "\n",
    "#model.embedding.weight.data.copy_(pretrained_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "\n",
    "#model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "#model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss() \n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    iterator.create_batches()\n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        predictions = model(batch.text)\n",
    "        \n",
    "        #print(f'prediction size:{predictions.size()}')\n",
    "        \n",
    "        outputs = torch.empty((predictions.size()[0],0)) #torch.zeros((predictions.size()[1],predictions.size()[0]))\n",
    "        outputs = outputs.to(device)\n",
    "        #print(outputs.size())\n",
    "        \n",
    "        for j in sorted_tag_lst:\n",
    "            out = getattr(batch, j)\n",
    "            out = torch.unsqueeze(out, -1)\n",
    "            out=out.to(device)\n",
    "            outputs=torch.cat((outputs,out),dim=1)\n",
    "            \n",
    "        \n",
    "        loss = criterion(predictions,outputs)\n",
    "        \n",
    "        #outputs = outputs.T\n",
    "        \n",
    "        \n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    \n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "\n",
    "            predictions = model(batch.text)\n",
    "            \n",
    "            outputs = torch.empty((predictions.size()[0],0)) #torch.zeros((predictions.size()[1],predictions.size()[0]))\n",
    "            outputs = outputs.to(device)\n",
    "            #print(outputs.size())\n",
    "\n",
    "            for j in sorted_tag_lst:\n",
    "                out = getattr(batch, j)\n",
    "                out = torch.unsqueeze(out, -1)\n",
    "                out=out.to(device)\n",
    "                outputs=torch.cat((outputs,out),dim=1)\n",
    "            \n",
    "            \n",
    "            loss = criterion(predictions, outputs)\n",
    "            #outputs = outputs.T\n",
    "            \n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 45s\n",
      "\tTrain Loss: 0.080 | Train Acc: -228.851318359375%\n",
      "\t Val. Loss: 0.059 |  Val. Acc: -229.1893768310547%\n",
      "Epoch: 02 | Epoch Time: 0m 47s\n",
      "\tTrain Loss: 0.057 | Train Acc: -234.7738800048828%\n",
      "\t Val. Loss: 0.050 |  Val. Acc: -213.4608917236328%\n",
      "Epoch: 03 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.049 | Train Acc: -232.67343139648438%\n",
      "\t Val. Loss: 0.046 |  Val. Acc: -215.85243225097656%\n",
      "Epoch: 04 | Epoch Time: 0m 44s\n",
      "\tTrain Loss: 0.045 | Train Acc: -214.67051696777344%\n",
      "\t Val. Loss: 0.043 |  Val. Acc: -224.436279296875%\n",
      "Epoch: 05 | Epoch Time: 0m 46s\n",
      "\tTrain Loss: 0.042 | Train Acc: -251.72097778320312%\n",
      "\t Val. Loss: 0.043 |  Val. Acc: -246.05360412597656%\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 5\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss = evaluate(model,valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'cnn-stackoverflow-model1.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('cnn-stackoverflow-model1.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "def predict_class(model, sentence, min_len = 4):\n",
    "    model.eval()\n",
    "    tokenized = [tok.text for tok in nlp.tokenizer(sentence)]\n",
    "    if len(tokenized) < min_len:\n",
    "        tokenized += ['<pad>'] * (min_len - len(tokenized))\n",
    "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
    "    tensor = torch.LongTensor(indexed).to(device)\n",
    "    tensor = tensor.unsqueeze(1)\n",
    "    preds = model(tensor)\n",
    "    preds = torch.squeeze(preds)\n",
    "    top = preds.argsort()\n",
    "    \n",
    "    return top[-3:].cpu().numpy()[::-1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[62 57 63]\n",
      "python\n",
      "pandas\n",
      "python-2.7\n"
     ]
    }
   ],
   "source": [
    "preds = predict_class(model, \"Pandas Series of Datetimes to Seconds?\")\n",
    "print(preds)\n",
    "#print(f'Predicted class is: {pred_class} = {LABEL.vocab.itos[pred_class]}')\n",
    "for i in preds:\n",
    "    print(sorted_tag_lst[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>.net</th>\n",
       "      <th>ajax</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>android</th>\n",
       "      <th>angularjs</th>\n",
       "      <th>apache</th>\n",
       "      <th>arrays</th>\n",
       "      <th>asp.net</th>\n",
       "      <th>asp.net-mvc</th>\n",
       "      <th>...</th>\n",
       "      <th>visual-studio-2010</th>\n",
       "      <th>wcf</th>\n",
       "      <th>web-services</th>\n",
       "      <th>windows</th>\n",
       "      <th>winforms</th>\n",
       "      <th>wordpress</th>\n",
       "      <th>wpf</th>\n",
       "      <th>xaml</th>\n",
       "      <th>xcode</th>\n",
       "      <th>xml</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>Obj-c, incorrect checksum for freed object - o...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>How to connect via HTTPS using Jsoup?</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>Python Pandas Series of Datetimes to Seconds S...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>jqGrid issue grouping - Duplicate rows get app...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>Create a List of primitive int?</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  .net  ajax  \\\n",
       "99995  Obj-c, incorrect checksum for freed object - o...     0     0   \n",
       "99996              How to connect via HTTPS using Jsoup?     0     0   \n",
       "99997  Python Pandas Series of Datetimes to Seconds S...     0     0   \n",
       "99998  jqGrid issue grouping - Duplicate rows get app...     0     0   \n",
       "99999                    Create a List of primitive int?     0     0   \n",
       "\n",
       "       algorithm  android  angularjs  apache  arrays  asp.net  asp.net-mvc  \\\n",
       "99995          0        0          0       0       0        0            0   \n",
       "99996          0        1          0       0       0        0            0   \n",
       "99997          0        0          0       0       0        0            0   \n",
       "99998          0        0          0       0       0        0            0   \n",
       "99999          0        0          0       0       0        0            0   \n",
       "\n",
       "       ...  visual-studio-2010  wcf  web-services  windows  winforms  \\\n",
       "99995  ...                   0    0             0        0         0   \n",
       "99996  ...                   0    0             0        0         0   \n",
       "99997  ...                   0    0             0        0         0   \n",
       "99998  ...                   0    0             0        0         0   \n",
       "99999  ...                   0    0             0        0         0   \n",
       "\n",
       "       wordpress  wpf  xaml  xcode  xml  \n",
       "99995          0    0     0      0    0  \n",
       "99996          0    0     0      0    0  \n",
       "99997          0    0     0      0    0  \n",
       "99998          0    0     0      0    0  \n",
       "99999          0    0     0      0    0  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
